{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxn to calculate regress and correl coeff maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Calculate correl and regress coeff map btwn two (time,lat,lon) xr dataarrays\n",
    "def gettemprcmap_loop(x3dnow,y3dnow,namebasenow):\n",
    "\n",
    "    # - Initialize nan DataArray same size as x3dnow\n",
    "    # --> new DataArray takes name of old though, so will need to rename\n",
    "    # (Apparently you can't initialize empty or full DataArrays yet still: https://github.com/pydata/xarray/issues/277)\n",
    "    rc2dnow = x3dnow.mean(dim='time') * np.nan\n",
    "    int2dnow = x3dnow.mean(dim='time') * np.nan\n",
    "    rcpval2dnow = x3dnow.mean(dim='time') * np.nan\n",
    "    cc2dnow = x3dnow.mean(dim='time') * np.nan\n",
    "    ccpval2dnow = x3dnow.mean(dim='time') * np.nan\n",
    "    stderr2dnow = x3dnow.mean(dim='time') * np.nan\n",
    "\n",
    "    # - Loop over each lat/lon combo\n",
    "    for ilat in range(x3dnow.lat.size):\n",
    "        for ilon in range(x3dnow.lon.size):\n",
    "            xnow = x3dnow[:,ilat,ilon]\n",
    "            ynow = y3dnow[:,ilat,ilon]\n",
    "            # - Get rid of any times where xnow or ynow is nan or inf\n",
    "            valsnow = (~xr.ufuncs.isnan(xnow))&(~xr.ufuncs.isnan(ynow))&(~xr.ufuncs.isinf(xnow))&(~xr.ufuncs.isinf(ynow))\n",
    "            if valsnow.sum()>=2:\n",
    "                #print([ilat,ilon])\n",
    "                ccnow = stats.pearsonr(xnow[valsnow],ynow[valsnow]) \n",
    "                cc2dnow[ilat,ilon] = ccnow[0]\n",
    "                ccpval2dnow[ilat,ilon] = ccnow[1]\n",
    "                #[rc2dnow[ilat,ilon], int2dnow[ilat,ilon], cc2dnow[ilat,ilon], pval2dnow[ilat,ilon], \n",
    "                # stderr2dnow[ilat,ilon]] = stats.linregress(xnow[valsnow],ynow[valsnow]) \n",
    "                linregnow = stats.linregress(xnow[valsnow],ynow[valsnow]) \n",
    "                rc2dnow[ilat,ilon] = linregnow[0]\n",
    "                int2dnow[ilat,ilon] = linregnow[1]\n",
    "                rcpval2dnow[ilat,ilon] = linregnow[3]\n",
    "                stderr2dnow[ilat,ilon] = linregnow[4]\n",
    "\n",
    "    # - Rename\n",
    "    rc2dnow.name = namebasenow+'_rc'\n",
    "    int2dnow.name = namebasenow+'_int'\n",
    "    rcpval2dnow.name = namebasenow+'_rc_pval'\n",
    "    cc2dnow.name = namebasenow+'_cc'\n",
    "    ccpval2dnow.name = namebasenow+'_cc_pval'\n",
    "    stderr2dnow.name = namebasenow+'_stderr'\n",
    "    \n",
    "    return [rc2dnow,int2dnow,rcpval2dnow,cc2dnow,ccpval2dnow,stderr2dnow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxn to generate Wilcoxon ranksum p-value maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Calculate wilcoxon rank sum p-val map btwn two (time,lat,lon) xr dataarrays\n",
    "def wrspvalmap_loop(x3dnow,y3dnow,namebasenow):\n",
    "\n",
    "    # - Initialize nan DataArray same size as x3dnow\n",
    "    # --> new DataArray takes name of old though, so will need to rename\n",
    "    pval2dnow = xr.full_like(x3dnow.mean(dim='time'), np.nan)\n",
    "\n",
    "    # - Loop over each lat/lon combo\n",
    "    for ilat in range(x3dnow.lat.size):\n",
    "        for ilon in range(x3dnow.lon.size):\n",
    "            xnow = x3dnow[:,ilat,ilon]\n",
    "            ynow = y3dnow[:,ilat,ilon]\n",
    "            # - Get rid of any times where xnow or ynow is nan or inf\n",
    "            xvalsnow = (~xr.ufuncs.isnan(xnow))&(~xr.ufuncs.isinf(xnow))\n",
    "            yvalsnow = (~xr.ufuncs.isnan(ynow))&(~xr.ufuncs.isinf(ynow))\n",
    "            if (xvalsnow.sum()>=1)&(yvalsnow.sum()>=1):\n",
    "                #print([ilat,ilon])\n",
    "                wrsnow = stats.ranksums(xnow[xvalsnow],ynow[yvalsnow]) \n",
    "                pval2dnow[ilat,ilon] = wrsnow[1]\n",
    "    \n",
    "    # - Rename\n",
    "    pval2dnow.name = namebasenow+'_wrs_pval'\n",
    "    \n",
    "    return pval2dnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxn to generate Kruskal-Wallis p-value maps (compares seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Calculate kruskal-wallis p-val map btwn four (time,lat,lon) xr dataarrays\n",
    "def kwpvalmap_loop(var1_3dnow,var2_3dnow,var3_3dnow,var4_3dnow,namebasenow):\n",
    "\n",
    "    # - Initialize nan DataArray same size as var1_3dnow\n",
    "    # --> new DataArray takes name of old though, so will need to rename\n",
    "    pval2dnow = xr.full_like(var1_3dnow.mean(dim='time'), np.nan)\n",
    "\n",
    "    # - Loop over each lat/lon combo\n",
    "    for ilat in range(var1_3dnow.lat.size):\n",
    "        for ilon in range(var1_3dnow.lon.size):\n",
    "            x1now = var1_3dnow[:,ilat,ilon]\n",
    "            x2now = var2_3dnow[:,ilat,ilon]\n",
    "            x3now = var3_3dnow[:,ilat,ilon]\n",
    "            x4now = var4_3dnow[:,ilat,ilon]\n",
    "            # - Get rid of any times where xnow is nan or inf\n",
    "            x1valsnow = (~xr.ufuncs.isnan(x1now))&(~xr.ufuncs.isinf(x1now))\n",
    "            x2valsnow = (~xr.ufuncs.isnan(x2now))&(~xr.ufuncs.isinf(x2now))\n",
    "            x3valsnow = (~xr.ufuncs.isnan(x3now))&(~xr.ufuncs.isinf(x3now))\n",
    "            x4valsnow = (~xr.ufuncs.isnan(x4now))&(~xr.ufuncs.isinf(x4now))\n",
    "            if (x1now[x1valsnow].sum()>=1)&(x2now[x2valsnow].sum()>=1)& \\\n",
    "               (x3now[x3valsnow].sum()>=1)&(x4now[x4valsnow].sum()>=1):\n",
    "                #print([ilat,ilon])\n",
    "                kwnow = stats.kruskal(x1now[x1valsnow],x2now[x2valsnow],\n",
    "                                      x3now[x3valsnow],x4now[x4valsnow]) \n",
    "                pval2dnow[ilat,ilon] = kwnow[1]\n",
    "    \n",
    "    # - Rename\n",
    "    pval2dnow.name = namebasenow+'_kw_pval'\n",
    "    \n",
    "    return pval2dnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxn to control false discovery rate in 2D maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Calculate minimum significant p-val threshold from false discovery rate (fdr)\n",
    "def controlfdr2d(pval2dnow,alphafdr):\n",
    "    pvalstack=pval2dnow.stack(x=['lat','lon'])\n",
    "    pvalstack=pvalstack[pvalstack.notnull()]\n",
    "    sortedpvalstack = pvalstack.sortby(pvalstack).values\n",
    "    N = sortedpvalstack.size\n",
    "    pfdrarr = alphafdr*np.arange(1,N+1)/N\n",
    "    if np.sum((sortedpvalstack-pfdrarr)<=0)>0:\n",
    "        pthreshfdr = sortedpvalstack[(pfdrarr-sortedpvalstack)>=0].max()\n",
    "    else:\n",
    "        pthreshfdr = 0\n",
    "    return pthreshfdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxn to find spots where p-value is below certain value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Find lat and lon where all p-values are small\n",
    "def find_where_pval_small(pvalmap,alpha):\n",
    "    # - Find spatial pts where all p-val are smaller than alpha\n",
    "    pvalmap_small_nonnan = pvalmap.where(pvalmap<alpha)\n",
    "    # - Get lat,lon where small p-vals are (https://stackoverflow.com/questions/40592630/get-coordinates-of-non-nan-values-of-xarray-dataset)\n",
    "    pvalmap_small_nonnan_stacked = pvalmap_small_nonnan.stack(x=['lat','lon'])\n",
    "    pvalmap_small = pvalmap_small_nonnan_stacked[pvalmap_small_nonnan_stacked.notnull()]\n",
    "    return [pvalmap_small.lon,pvalmap_small.lat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxn for boxplotting values over EEZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allenln_eezmask_enlnwrspval(varnow,eeznames,eezmask,dfeeznamesmask):\n",
    "    varallnow, varennow, varlnnow = [], [], []\n",
    "    enlnpvalnow = np.full(len(eeznames), np.nan) \n",
    "    for ieez in range(0,len(eeznames)):\n",
    "        eeznumnow = dfeeznamesmask['numbers'][dfeeznamesmask['names']==eeznames[ieez]].values\n",
    "        allnow = varnow.where(np.isin(eezmask,eeznumnow)).values\n",
    "        allnow = allnow[~np.isnan(allnow)]\n",
    "        ennow = varnow[onienln==1].where(np.isin(eezmask,eeznumnow)).values\n",
    "        ennow = ennow[~np.isnan(ennow)]\n",
    "        lnnow = varnow[onienln==-1].where(np.isin(eezmask,eeznumnow)).values\n",
    "        lnnow = lnnow[~np.isnan(lnnow)]\n",
    "        if len(ennow)>1 and len(lnnow)>1:\n",
    "            _,enlnpvalnow[ieez] = stats.ranksums(ennow,lnnow)\n",
    "        varallnow.append(allnow)\n",
    "        varennow.append(ennow)\n",
    "        varlnnow.append(lnnow)\n",
    "\n",
    "    return varallnow, varennow, varlnnow, enlnpvalnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seas_eezmask_seaskwpval(varnow,eeznames,eezmask,dfeeznamesmask):\n",
    "    varwinnow, varsprnow, varsumnow, varautnow = [], [], [], []\n",
    "    seaspvalnow = np.full(len(eeznames), np.nan) \n",
    "    for ieez in range(0,len(eeznames)):\n",
    "        eeznumnow = dfeeznamesmask['numbers'][dfeeznamesmask['names']==eeznames[ieez]].values\n",
    "        winnow = varnow.sel(time=varnow['time.season']=='DJF'\n",
    "                  ).where(np.isin(eezmask,eeznumnow)).values\n",
    "        winnow = winnow[~np.isnan(winnow)]\n",
    "        sprnow = varnow.sel(time=varnow['time.season']=='MAM'\n",
    "                  ).where(np.isin(eezmask,eeznumnow)).values\n",
    "        sprnow = sprnow[~np.isnan(sprnow)]\n",
    "        sumnow = varnow.sel(time=varnow['time.season']=='JJA'\n",
    "                  ).where(np.isin(eezmask,eeznumnow)).values\n",
    "        sumnow = sumnow[~np.isnan(sumnow)]\n",
    "        autnow = varnow.sel(time=varnow['time.season']=='SON'\n",
    "                  ).where(np.isin(eezmask,eeznumnow)).values\n",
    "        autnow = autnow[~np.isnan(autnow)]\n",
    "        if len(winnow)>1 and len(sprnow)>1 and len(sumnow)>1 and len(autnow)>1:\n",
    "            _,seaspvalnow[ieez] = stats.kruskal(winnow, sprnow, sumnow, autnow)\n",
    "        varwinnow.append(winnow)\n",
    "        varsprnow.append(sprnow)\n",
    "        varsumnow.append(sumnow)\n",
    "        varautnow.append(autnow)\n",
    "    return varwinnow, varsprnow, varsumnow, varautnow, seaspvalnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_box_color(bp, color):\n",
    "    plt.setp(bp['boxes'], color=color)\n",
    "    plt.setp(bp['whiskers'], color=color)\n",
    "    plt.setp(bp['caps'], color=color)\n",
    "    plt.setp(bp['medians'], color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxn to control false discovery rate in 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlfdr1d(pvals1d,alphafdr):\n",
    "    pvals1d = pvals1d[~np.isnan(pvals1d)]\n",
    "    sortedpvals = np.sort(pvals1d)\n",
    "    N = sortedpvals.size\n",
    "    pfdrarr = alphafdr*np.arange(1,N+1)/N\n",
    "    if np.sum((sortedpvals-pfdrarr)<=0)>0:\n",
    "        pthreshfdr = sortedpvals[(sortedpvals-pfdrarr)<=0].max()\n",
    "    else:\n",
    "        pthreshfdr = 0\n",
    "    return pthreshfdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxn for calculating pO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from Allison Smith's github:\n",
    "# https://github.com/kallisons/pO2_conversion/function_pO2.py\n",
    "# with some modifications for style and units\n",
    "\n",
    "# pO2 Conversion:\n",
    "# Oxygen concentration is converted to percent oxygen saturation using the equations from Garcia and Gordon (1992).\n",
    "# The percent oxygen saturation is divided by 0.21 (the fractional atmospheric concentration of oxygen) to get pO2 in atmospheres (atm).\n",
    "# pO2 is then corrected for the hydrostatic pressure at depth (Enns et al., 1965).\n",
    "# The units for pO2 are converted to kilopascals (kPa), the SI Units for pressure.\n",
    "# References:\n",
    "# - García HE, Gordon LI (1992) Oxygen solubility in seawater: Better fitting equations. Limnology and Oceanography, 37, 1307–1312.\n",
    "# - Enns T, Scholander PF, Bradstreet ED (1965) Effect of hydrostatic pressure on gases dissolved in water. The Journal of Physical Chemistry, 69, 389–391.\n",
    " \n",
    "# UNITS:\n",
    "# o2 in umol/Kg\n",
    "# temp in Celsius (= potential temperature, NOT in situ)\n",
    "# sal in psu\n",
    "# depth in m\n",
    "# po2 returned in kPa\n",
    "\n",
    "def calc_po2(o2, temp, sal, depth):\n",
    "    \"\"\"Computes po2 from o2 [umol/kg], potential temperature [Celsius], salinity [psu], depth [m].\"\"\"\n",
    "    a_0 = 5.80871\n",
    "    a_1 = 3.20291\n",
    "    a_2 = 4.17887\n",
    "    a_3 = 5.10006\n",
    "    a_4 = -9.86643e-2\n",
    "    a_5 = 3.80369\n",
    "    b_0 = -7.01577e-3\n",
    "    b_1 = -7.70028e-3\n",
    "    b_2 =  -1.13864e-2\n",
    "    b_3 = -9.51519e-3\n",
    "    c_0 = -2.75915E-7\n",
    "\n",
    "    tt = 298.15 - temp\n",
    "    tk = 273.15 + temp\n",
    "    ts = np.log(tt / tk)\n",
    "\n",
    "    #correct for pressure at depth\n",
    "    V = 32e-6 #partial molar volume of O2 (m3/mol)\n",
    "    R = 8.31 #Gas constant [J/mol/K]\n",
    "    db2Pa = 1e4 #convert pressure: decibar to Pascal\n",
    "    atm2Pa = 1.01325e5 #convert pressure: atm to Pascal\n",
    "\n",
    "    #calculate pressure in dB from depth in m\n",
    "    pres = depth*(1.0076+depth*(2.3487e-6 - depth*1.2887e-11));\n",
    "\n",
    "    #convert pressure from decibar to pascal\n",
    "    dp = pres*db2Pa\n",
    "    pCor = np.exp((V*dp)/(R*(temp+273.15)))\n",
    "\n",
    "    o2_sat = np.exp(a_0 + a_1*ts + a_2*ts**2 + a_3*ts**3 + a_4*ts**4 + a_5*ts**5 + sal*(b_0 + b_1*ts + b_2*ts**2 + b_3*ts**3) + c_0*sal**2)\n",
    "    \n",
    "    o2_alpha = (o2_sat / 0.21)  #0.21 is atmospheric composition of O2\n",
    "    kh = o2_alpha*pCor\n",
    "    po2 = (o2 / kh)*101.32501  #convert po2 from atm to kPa\n",
    "\n",
    "    return po2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fxns for performing + plotting quotient analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quotient_analysis_full(ivfull,dvfull,ivname,dvname,nbins,nruns,plothists):\n",
    "    # IV for indy var, DV for dep var\n",
    "    iv = ivfull.where(dvfull.notnull())\n",
    "    dv = dvfull.where(ivfull.notnull())\n",
    "    \n",
    "    ivminf = np.floor(10*iv.min())/10\n",
    "    ivmaxc = np.ceil(10*iv.max())/10\n",
    "    binedges = np.linspace(ivminf,ivmaxc,nbins+1)\n",
    "    \n",
    "    if plothists==1:\n",
    "        fig,axes = plt.subplots(figsize=(7,5),nrows=2,ncols=2)\n",
    "        ivfull.plot.hist(ax=axes[0][0],bins=20); axes[0][0].set_title('IV - all values');\n",
    "        iv.plot.hist(ax=axes[0][1],bins=20); axes[0][1].set_title('IV - assoc w/ DV values');\n",
    "        dvfull.plot.hist(ax=axes[1][0],bins=20); axes[1][0].set_title('DV - all values');\n",
    "        dv.plot.hist(ax=axes[1][1],bins=20); axes[1][1].set_title('DV - assoc w/ IV values');\n",
    "        fig.tight_layout()\n",
    "    \n",
    "    dsqa = xr.merge([iv, dv])\n",
    "    dfqa = dsqa.to_dataframe()\n",
    "    dfqa.rename(columns={ivname: 'IV', dvname: 'DV'}, inplace=True)\n",
    "    dfqa.reset_index(inplace=True)\n",
    "    dfqa = dfqa.dropna(subset=['IV','DV'], how='any')\n",
    "\n",
    "    ivcounts, dvcounts, dvquot = quotient_analysis(dfqa,binedges)\n",
    "\n",
    "    # Bernal et al. 2007: replace=FALSE in the code, but in the paper it says replace=TRUE\n",
    "    # --> I think I'll go w/ what the paper says? though difference\n",
    "    # between the two methods is small\n",
    "    dfsimreplaceF = pd.DataFrame(); dfsimreplaceT = pd.DataFrame()\n",
    "    for i in range(nruns):\n",
    "        dfsimreplaceF=pd.concat([dfsimreplaceF,dfqa['DV'].sample(\n",
    "            n=len(dfqa['DV']), replace=False).reset_index(\n",
    "            drop=True)], axis=1).rename(columns={'DV':i})\n",
    "        dfsimreplaceT=pd.concat([dfsimreplaceT,dfqa['DV'].sample(\n",
    "            n=len(dfqa['DV']), replace=True).reset_index(\n",
    "            drop=True)], axis=1).rename(columns={'DV':i})\n",
    "\n",
    "    dfsimreplaceF = dfsimreplaceF.assign(IV=dfqa['IV'].values)\n",
    "    dfsimreplaceT = dfsimreplaceT.assign(IV=dfqa['IV'].values)\n",
    "\n",
    "    quotsimreplaceF = pd.DataFrame(); quotsimreplaceT = pd.DataFrame()\n",
    "    for i in range(nruns):\n",
    "        _,_,quotsimreplaceFtemp = quotient_analysis(\n",
    "            dfsimreplaceF[[i,'IV']].rename(columns={i:'DV'}),binedges)\n",
    "        quotsimreplaceF = pd.concat([quotsimreplaceF,quotsimreplaceFtemp], axis=1)\n",
    "        _,_,quotsimreplaceTtemp = quotient_analysis(\n",
    "            dfsimreplaceT[[i,'IV']].rename(columns={i:'DV'}),binedges)\n",
    "        quotsimreplaceT = pd.concat([quotsimreplaceT,quotsimreplaceTtemp], axis=1)\n",
    "\n",
    "    qlimsreplaceT = quotsimreplaceT.quantile([0.025, 0.975], axis=1)\n",
    "    qlimsreplaceF = quotsimreplaceF.quantile([0.025, 0.975], axis=1)\n",
    "    bincenters = (binedges[1:] + binedges[:-1])/2\n",
    "\n",
    "    return dfqa['IV'], binedges, bincenters, ivcounts, dvcounts, dvquot, qlimsreplaceT, qlimsreplaceF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quotient_analysis(dfqa,binedges):\n",
    "    # IV for indy var, DV for dep var\n",
    "    dfqa['IV_bin'] = pd.cut(dfqa['IV'],binedges)\n",
    "    ivcounts = dfqa.groupby('IV_bin')['IV'].count()\n",
    "    dvcounts = dfqa.groupby('IV_bin')['DV'].sum()\n",
    "    ivfreq = ivcounts*100/ivcounts.sum()\n",
    "    dvfreq = dvcounts*100/dvcounts.sum()\n",
    "    dvquot = dvfreq/ivfreq\n",
    "    return ivcounts, dvcounts, dvquot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_atp(row):\n",
    "    if row['quot']<row['2pt5p']:\n",
    "        return -1 # avoidance\n",
    "    if row['quot']>=row['2pt5p'] and row['quot']<=row['97pt5p']:\n",
    "        return 0 # tolerance\n",
    "    if row['quot']>row['97pt5p']:\n",
    "        return 1 # preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfatp(qlimsreplaceT,dvquot,binedges):\n",
    "    dfatp = pd.concat([qlimsreplaceT.transpose(),dvquot], axis=1)\n",
    "    dfatp = dfatp.rename(columns={0:'quot', 0.025:'2pt5p', 0.975:'97pt5p'})\n",
    "    dfatp['ATP'] = dfatp.apply(define_atp, axis=1)\n",
    "    dfatp.reset_index(inplace=True)\n",
    "    dfatp = pd.concat([dfatp,pd.Series(binedges[0:-1],name='lbinedges'),\n",
    "                      pd.Series(binedges[1:],name='rbinedges')], axis=1)    \n",
    "    return dfatp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
